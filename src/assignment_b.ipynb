{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3335886c",
   "metadata": {},
   "source": [
    "# Spam Filter  \n",
    "**Data Science I, Assignment B**  \n",
    "**Student:** Fabian Augschöll  \n",
    "**Date:** June 2025  \n",
    "\n",
    "**Abstract**  \n",
    "In this notebook we build and evaluate three spam‑classification models (Naive Bayes, Logistic Regression, SVM) on the Apache SpamAssassin corpus. We’ll also experiment with different text‑preprocessing pipelines to maximize combined precision + recall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb49afe7",
   "metadata": {},
   "source": [
    "## Objectives  \n",
    "1. Load “easy_ham_2” vs. “spam_2” emails  \n",
    "2. Build a flexible preprocessing pipeline  \n",
    "3. Vectorize text with a bag‑of‑words model  \n",
    "4. Train & evaluate three classifiers  \n",
    "5. Experiment with preprocessing hyperparameters  \n",
    "6. Demonstrate the best model on a fresh sample  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100e4695",
   "metadata": {},
   "source": [
    "## Imports & helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "365bae74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re\n",
    "os.chdir('..')\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score\n",
    "\n",
    "def load_emails(directory, label):\n",
    "    \"\"\"Load all .txt emails in `directory`, assign label 0=ham, 1=spam.\"\"\"\n",
    "    emails = []\n",
    "    for fname in os.listdir(directory):\n",
    "        path = os.path.join(directory, fname)\n",
    "        try:\n",
    "            with open(path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "                emails.append((f.read(), label))\n",
    "        except Exception:\n",
    "            pass\n",
    "    return emails\n",
    "\n",
    "class EmailPreprocessor:\n",
    "    \"\"\"Flexible email cleaner: strip headers, lowercase, URL/NUM replacement, punctuation removal.\"\"\"\n",
    "    def __init__(self, strip_headers=True, lowercase=True,\n",
    "                 remove_punct=True, replace_urls=True, replace_nums=True):\n",
    "        self.strip_headers, self.lowercase = strip_headers, lowercase\n",
    "        self.remove_punct, self.replace_urls = remove_punct, replace_urls\n",
    "        self.replace_nums = replace_nums\n",
    "\n",
    "    def preprocess(self, text):\n",
    "        if self.strip_headers:\n",
    "            parts = text.split('\\n\\n', 1)\n",
    "            text = parts[1] if len(parts) > 1 else parts[0]\n",
    "        if self.lowercase:\n",
    "            text = text.lower()\n",
    "        if self.replace_urls:\n",
    "            text = re.sub(r'http[s]?://\\S+', 'URL', text)\n",
    "        if self.replace_nums:\n",
    "            text = re.sub(r'\\d+', 'NUMBER', text)\n",
    "        if self.remove_punct:\n",
    "            text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "        return ' '.join(text.split())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd3273e",
   "metadata": {},
   "source": [
    "## Data loading\n",
    "We’ll load both ham and spam folders, shuffle, then split out texts & labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44aa357c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2798 emails: 1397 spam, 1401 ham.\n"
     ]
    }
   ],
   "source": [
    "def prepare_data(base_path='data'):\n",
    "    ham = load_emails(os.path.join(base_path, 'easy_ham_2'), 0)\n",
    "    spam = load_emails(os.path.join(base_path, 'spam_2'), 1)\n",
    "    data = ham + spam\n",
    "    np.random.seed(42)\n",
    "    np.random.shuffle(data)\n",
    "    texts, labels = zip(*data)\n",
    "    return list(texts), np.array(labels)\n",
    "\n",
    "texts, labels = prepare_data('data')\n",
    "print(f\"Loaded {len(texts)} emails: {labels.sum()} spam, {len(labels)-labels.sum()} ham.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bae504",
   "metadata": {},
   "source": [
    "## Text preprocessing\n",
    "We’ll use the default configuration (strip headers, lowercase, remove punctuation, replace URLs & numbers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2fc4098",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = EmailPreprocessor()\n",
    "processed_texts = [pre.preprocess(t) for t in texts]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed51a9fc",
   "metadata": {},
   "source": [
    "## Feature extraction  \n",
    "Limit to top 1,000 features; filter out English stop‑words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ec91a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/test sizes: 1958/840\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(max_features=1000, stop_words='english')\n",
    "X = vectorizer.fit_transform(processed_texts)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, labels, test_size=0.3, stratify=labels, random_state=42)\n",
    "print(f\"Train/test sizes: {X_train.shape[0]}/{X_test.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cf46ac",
   "metadata": {},
   "source": [
    "## Model training & evaluation\n",
    "We’ll train Naive Bayes, Logistic Regression, and linear SVM, then report precision & recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81c00e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Naive Bayes ---\n",
      "Precision: 0.987, Recall: 0.726\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Ham       0.78      0.99      0.88       421\n",
      "        Spam       0.99      0.73      0.84       419\n",
      "\n",
      "    accuracy                           0.86       840\n",
      "   macro avg       0.89      0.86      0.86       840\n",
      "weighted avg       0.89      0.86      0.86       840\n",
      "\n",
      "--- Logistic Regression ---\n",
      "Precision: 0.993, Recall: 0.981\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Ham       0.98      0.99      0.99       421\n",
      "        Spam       0.99      0.98      0.99       419\n",
      "\n",
      "    accuracy                           0.99       840\n",
      "   macro avg       0.99      0.99      0.99       840\n",
      "weighted avg       0.99      0.99      0.99       840\n",
      "\n",
      "--- SVM ---\n",
      "Precision: 0.978, Recall: 0.976\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Ham       0.98      0.98      0.98       421\n",
      "        Spam       0.98      0.98      0.98       419\n",
      "\n",
      "    accuracy                           0.98       840\n",
      "   macro avg       0.98      0.98      0.98       840\n",
      "weighted avg       0.98      0.98      0.98       840\n",
      "\n",
      "**Best model:** Logistic Regression\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def train_and_report(X_tr, X_te, y_tr, y_te):\n",
    "    models = {\n",
    "        'Naive Bayes': MultinomialNB(),\n",
    "        'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "        'SVM': SVC(kernel='linear', probability=True)\n",
    "    }\n",
    "    results = {}\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_tr, y_tr)\n",
    "        y_pred = model.predict(X_te)\n",
    "        p, r = precision_score(y_te, y_pred), recall_score(y_te, y_pred)\n",
    "        print(f\"--- {name} ---\")\n",
    "        print(f\"Precision: {p:.3f}, Recall: {r:.3f}\")\n",
    "        print(classification_report(y_te, y_pred, target_names=['Ham', 'Spam']))\n",
    "        results[name] = {'model': model, 'precision': p, 'recall': r}\n",
    "    return results\n",
    "\n",
    "results = train_and_report(X_train, X_test, y_train, y_test)\n",
    "best_name = max(results, key=lambda k: results[k]['precision']+results[k]['recall'])\n",
    "print(f\"**Best model:** {best_name}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f88baa",
   "metadata": {},
   "source": [
    "## Demonstration\n",
    "Try the best model on a new email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "620c2e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: SPAM (Ham=0.29, Spam=0.71)\n"
     ]
    }
   ],
   "source": [
    "sample = \"Subject: Win money now! Click http://spam.link\"\n",
    "proc = pre.preprocess(sample)\n",
    "vec = vectorizer.transform([proc])\n",
    "pred = results[best_name]['model'].predict(vec)[0]\n",
    "prob = results[best_name]['model'].predict_proba(vec)[0]\n",
    "print(f\"Prediction: {'SPAM' if pred else 'HAM'} (Ham={prob[0]:.2f}, Spam={prob[1]:.2f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14742db3",
   "metadata": {},
   "source": [
    "## Hyperparameter experimentation\n",
    "We’ll compare four settings by combined precision+recall on Naive Bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "038b6793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config 1: P=0.987, R=0.726, Sum=1.713\n",
      "Config 2: P=0.994, R=0.842, Sum=1.837\n",
      "Config 3: P=0.987, R=0.726, Sum=1.713\n",
      "Config 4: P=0.987, R=0.726, Sum=1.713\n",
      "\n",
      "**Best config:** {'strip_headers': False, 'lowercase': True, 'remove_punct': True, 'replace_urls': True, 'replace_nums': True} (Sum=1.837)\n"
     ]
    }
   ],
   "source": [
    "def hyperparam_experiment(texts, labels):\n",
    "    configs = [\n",
    "        {'strip_headers': True,  'lowercase': True,  'remove_punct': True,  'replace_urls': True,  'replace_nums': True},\n",
    "        {'strip_headers': False, 'lowercase': True,  'remove_punct': True,  'replace_urls': True,  'replace_nums': True},\n",
    "        {'strip_headers': True,  'lowercase': False, 'remove_punct': True,  'replace_urls': True,  'replace_nums': True},\n",
    "        {'strip_headers': True,  'lowercase': True,  'remove_punct': False, 'replace_urls': True,  'replace_nums': True},\n",
    "    ]\n",
    "    best, best_cfg = 0, None\n",
    "    for i, cfg in enumerate(configs, 1):\n",
    "        pre = EmailPreprocessor(**cfg)\n",
    "        proc = [pre.preprocess(t) for t in texts]\n",
    "        X = CountVectorizer(max_features=1000, stop_words='english').fit_transform(proc)\n",
    "        Xtr, Xte, ytr, yte = train_test_split(X, labels, test_size=0.3,\n",
    "                                              random_state=42, stratify=labels)\n",
    "        model = MultinomialNB().fit(Xtr, ytr)\n",
    "        yp = model.predict(Xte)\n",
    "        p, r = precision_score(yte, yp), recall_score(yte, yp)\n",
    "        print(f\"Config {i}: P={p:.3f}, R={r:.3f}, Sum={p+r:.3f}\")\n",
    "        if p+r > best:\n",
    "            best, best_cfg = p+r, cfg\n",
    "    print(f\"\\n**Best config:** {best_cfg} (Sum={best:.3f})\")\n",
    "\n",
    "hyperparam_experiment(texts, labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca03c74",
   "metadata": {},
   "source": [
    "## Conclusions  \n",
    "- **Best classifier:** Logistic Regression (Precision=0.993, Recall=0.981)  \n",
    "- **Best preprocessing:** headers _on_, lowercase _on_, punctuation removed, URLs & numbers replaced  \n",
    "  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
